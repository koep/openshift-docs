// Module included in the following assemblies:
//
// * networking/ovn_kubernetes_network_provider/deploying-egress-router-ovn-redirection.adoc

[id="nw-egress-router-redirect-mode-ovn_{context}"]
= Deploying an egress router pod in redirect mode

You can deploy an egress router pod to redirect traffic from its own reserved source IP address to one or more destination IP addresses.

After you add an egress router pod, the client pods that need to use the reserved source IP address must be modified to connect to the egress router rather than connecting directly to the destination IP.

.Prerequisites

* Install the OpenShift CLI (`oc`).
* Log in as a user with `cluster-admin` privileges.

.Procedure

. Create a network attachment definition.

. Create an egress router pod.

. To ensure that other pods can find the IP address of the egress router pod, create a service that uses the egress router pod, as in the following example:
+
[source,yaml]
----
apiVersion: v1
kind: Service
metadata:
  name: egress-1
spec:
  ports:
  - name: database
    protocol: TCP
    port: 3306
  type: ClusterIP
  selector:
    name: egress-router-pod
----
+
After you create the service, your pods can connect to the service. The egress router pod redirects the connection to the corresponding port on the destination IP address. The connections originate from the reserved source IP address.

.Verification

To verify that the egress router pod started and has the secondary network interface, complete the following procedure:

. View the events for the egress router pod:
+
[source,terminal]
----
$ oc get events --field-selector involvedObject.name=egress-router-pod
----
+
If the pod references the network attachment definition, the previous command returns output that is similar to the following:
+
.Example output
+
[source,terminal]
----
LAST SEEN   TYPE     REASON           OBJECT                  MESSAGE
5m4s        Normal   Scheduled        pod/egress-router-pod   Successfully assigned default/egress-router-pod to ci-ln-9x2bnsk-f76d1-j2v6g-worker-c-24g65
5m3s        Normal   AddedInterface   pod/egress-router-pod   Add eth0 [10.129.2.31/23]
5m3s        Normal   AddedInterface   pod/egress-router-pod   Add net1 [192.168.12.99/24] from default/egress-router-redirect
----

. Optional: View the routing table for the egress router pod.
// Terminology from support-collecting-network-trace.adoc
.. Get the node name for the egress router pod:
+
[source,terminal]
----
$ POD_NODENAME=$(oc get pod egress-router-pod -o jsonpath="{.spec.nodeName}")
----

.. Enter into a debug session on the target node. This step instantiates a debug pod called `<node_name>-debug`:
+
[source,terminal]
----
$ oc debug node/$POD_NODENAME
----

.. Set `/host` as the root directory within the debug shell. The debug pod mounts the root file system of the host in `/host` within the pod. By changing the root directory to `/host`, you can run binaries from the executable paths of the host:
+
[source,terminal]
----
# chroot /host
----

.. From within the `chroot` environment console, get the container ID:
+
[source,terminal]
----
# crictl ps --name egress-router-redirect | awk '{print $1}'
----
+
.Example output
[source,terminal]
----
CONTAINER
bac9fae69ddb6
----

.. Determine the process ID of the container. In this example, the container ID is `bac9fae69ddb6`:
+
[source,terminal]
----
# crictl inspect -o yaml bac9fae69ddb6 | grep 'pid:' | awk '{print $2}'
----
+
.Example output
[source,terminal]
----
68857
----

.. Enter the network namespace of the container:
+
[source,terminal]
----
# nsenter -n -t 68857
----

.. Display the routing table:
+
[source,terminal]
----
# ip route
----
+
In the following example output, the `net1` network interface is the default route. Traffic for the cluster network uses the `eth0` network interface. Traffic for the `192.168.12.0/24` network uses the `net1` network interface and originates from the reserved source IP address `192.168.12.99`. The pod routes all other traffic to the gateway at IP address `192.168.12.1`. Routing for the service network is not shown.
+
.Example output
[source,terminal]
----
default via 192.168.12.1 dev net1
10.129.2.0/23 dev eth0 proto kernel scope link src 10.129.2.31
192.168.12.0/24 dev net1 proto kernel scope link src 192.168.12.99
192.168.12.1 dev net1
----
